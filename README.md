# Job Portals Scrapping & Analysis

This repository contains Jupyter notebooks, CSV files, and an HTML document that collectively present the process involved in scraping job data from web portals, cleaning the data, model learning, evaluation, and dashboard creation to highlight predictions.

## Process Overview

1. **Web Scraping:**
   - Job data was collected from Indeed and Glassdoor platforms.

2. **Data Cleaning:**
   - Over 5000 raw data entries were cleaned to prepare them for analysis.

3. **Model Learning:**
   - Various regression models were experimented with to find the best fit for the data.

4. **Job Categories:**
   - Specifically targeted roles such as Data Scientist, Big Data Analyst, and Machine Learning were scraped.

5. **Model Evaluation:**
   - Performance metrics were utilized to evaluate and compare the models.

6. **Integrate the Model:**
   - A dashboard was created to visually present and highlight the model predictions.

## Repository Contents

- Jupyter notebooks:
  - Cleaning1.ipynb
  - Glassdoor.ipynb
  - Model.ipynb
  - Visualization with interpretation (1).ipynb
  - etc.

- CSV files:
  - Dataset.csv
  - Final Imputed.csv
  - indeed_dataScientist.csv
  - etc.

- Other Files:
  - Dashboard.html
  - README.md
  - Presentation.pdf: Presentation slides

## Usage
- **Jupyter Notebooks:** These contain the code used for data cleaning, model building, and visualization.
- **CSV Files:** Contain the datasets utilized for the analysis.
- **Dashboard.html:** The HTML file containing the dashboard to showcase model predictions.

## How to Use
- The Jupyter notebooks can be opened and run in an environment supporting Python and Jupyter.

## Contributors
- Kaveri Kayra

---
